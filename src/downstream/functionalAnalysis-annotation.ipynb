{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "daf68633",
   "metadata": {},
   "source": [
    "# Annotation of transcript isoforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0eccb06",
   "metadata": {},
   "source": [
    "- Transcript isoforms with coding region were annotated using several softwares:\n",
    "    - Bakta (prokaryotic annotation)\n",
    "    - KEGG for eukaryotes and viruses (BlastKOALA; https://www.kegg.jp/blastkoala/)\n",
    "    - dbCAN3 (CAZy annotation)\n",
    "    - Anvio (KEGG module completeness)\n",
    "    - Top alignment row from BLASTn alignments (all assembled 10M transcript isoforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97a80ad",
   "metadata": {},
   "source": [
    "### 1) Bakta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff1e2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda env\n",
    "conda activate bakta\n",
    "\n",
    "# codes\n",
    "bakta_db download --output db --type full\n",
    "bakta --db ../../../Bakta/db diff-expressed-genes.fasta --verbose --output results/ --threads 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58280e7",
   "metadata": {},
   "source": [
    "### 2) dbCAN3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5b9334",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda activate dbCAN3\n",
    "\n",
    "# automatically download and prepare databases\n",
    "run_dbcan database --db_dir db\n",
    "\n",
    "# run dbCAN3 for CAZy annotation\n",
    "run_dbcan CAZyme_annotation --input_raw_data diff-expressed-genes.fasta --out_dir dbCAN3_annotation --db_dir ../db --mode meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961826c6",
   "metadata": {},
   "source": [
    "### 3) Anvi'o with dev version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb47ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install anvio-dev version: https://anvio.org/install/linux/dev/\n",
    "conda create -y --name anvio-dev python=3.10\n",
    "conda activate anvio-dev\n",
    "\n",
    "# install dependencies\n",
    "conda install -y -c conda-forge -c bioconda python=3.10 \\\n",
    "        sqlite=3.46 prodigal idba mcl muscle=3.8.1551 famsa hmmer diamond \\\n",
    "        blast megahit spades bowtie2 bwa graphviz \"samtools>=1.9\" \\\n",
    "        trimal iqtree trnascan-se fasttree vmatch r-base r-tidyverse \\\n",
    "        r-optparse r-stringi r-magrittr bioconductor-qvalue meme ghostscript \\\n",
    "        nodejs=20.12.2\n",
    "\n",
    "# try this, if it doesn't install, don't worry (it is sad, but OK):\n",
    "conda install -y -c bioconda fastani\n",
    "\n",
    "# setting up the local copy of the anviâ€™o codebase\n",
    "mkdir -p ~/github && cd ~/github/\n",
    "git clone --recursive https://github.com/merenlab/anvio.git\n",
    "\n",
    "# installing the Python dependencies\n",
    "export CC=/usr/bin/clang\n",
    "export CXX=/usr/bin/clang++\n",
    "\n",
    "# and:\n",
    "cd ~/github/anvio/\n",
    "pip install -r requirements.txt\n",
    "\n",
    "# linking conda environment and the codebase\n",
    "cat <<EOF >${CONDA_PREFIX}/etc/conda/activate.d/anvio.sh\n",
    "# creating an activation script for the the conda environment for anvi'o\n",
    "# development branch so (1) Python knows where to find anvi'o libraries,\n",
    "# (2) the shell knows where to find anvi'o programs, and (3) every time\n",
    "# the environment is activated it synchronizes with the latest code from\n",
    "# active GitHub repository:\n",
    "export PYTHONPATH=\\$PYTHONPATH:\\$HOME/github/anvio/\n",
    "export PATH=\\$PATH:\\$HOME/github/anvio/bin:\\$HOME/github/anvio/sandbox\n",
    "echo -e \"\\033[1;34mUpdating from anvi'o GitHub \\033[0;31m(press CTRL+C to cancel)\\033[0m ...\"\n",
    "cd \\$HOME/github/anvio && git pull && cd -\n",
    "EOF\n",
    "\n",
    "# check if it worked\n",
    "which anvi-self-test\n",
    "anvi-self-test -v\n",
    "\n",
    "# final installation check\n",
    "anvi-self-test --suite mini\n",
    "\n",
    "# now to start using anvio for pathway analysis, do the following\n",
    "# set up KEGG database on the cluster - this code will download the db: https://anvio.org/tutorials/fmt-mag-metabolism/\n",
    "anvi-setup-kegg-data\n",
    "\n",
    "# then check if it is being called correctly\n",
    "# learn where the MODULES.db is:\n",
    "export ANVIO_MODULES_DB=`python -c \"import anvio; import os; print(os.path.join(os.path.dirname(anvio.__file__), 'data/misc/KEGG/MODULES.db'))\"`\n",
    "\n",
    "# print the path so you can see where it is located\n",
    "echo $ANVIO_MODULES_DB\n",
    "\n",
    "# check the hash of the MODULES.db contents\n",
    "anvi-db-info $ANVIO_MODULES_DB\n",
    "\n",
    "# reformat fasta file so anvio knows how to read it\n",
    "anvi-script-reformat-fasta upregulated.fasta --simplify-names --output-file upregulated.fa --report-file upregulated_report.txt\n",
    "anvi-script-reformat-fasta downregulated.fasta --simplify-names --output-file downregulated.fa --report-file downregulated_report.txt\n",
    "\n",
    "# build a contig database for anvio, one for upregulated transcripts and another one for downregulated transcripts\n",
    "anvi-gen-contigs-database --contigs-fasta upregulated.fa --project-name FE_upregulated --output-db-path FE_upregulated.db --num-threads 4\n",
    "anvi-gen-contigs-database --contigs-fasta downregulated.fa --project-name FE_downregulated --output-db-path FE_downregulated.db --num-threads 4\n",
    "\n",
    "# then annotate the up and downregulated transcripts with KOfam hits\n",
    "anvi-run-kegg-kofams -c FE_upregulated.db -T 4\n",
    "anvi-run-kegg-kofams -c FE_downregulated.db -T 4\n",
    "\n",
    "# estimate metabolism completeness metrics\n",
    "anvi-estimate-metabolism -c FE_upregulated.db -O FE_upregulated_metabolism\n",
    "anvi-estimate-metabolism -c FE_downregulated.db -O FE_downregulated_metabolism\n",
    "# here we can get a table showing module completeness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aeb36f0",
   "metadata": {},
   "source": [
    "### 4) Top hit from BLASTn alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a94b347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda env\n",
    "conda activate blast\n",
    "\n",
    "# download most up to date databases from NCBI\n",
    "update_blastdb.pl --decompress nt\n",
    "update_blastdb.pl --decompress nr\n",
    "\n",
    "# exported db to \n",
    "export BLASTDB=/home/hfm/db/blast/nt:/home/hfm/db/blast/nr\n",
    "\n",
    "# run BLASTn with the goal of retaining only the top row from alignments as a proxy of transcript host\n",
    "blastn -db nt -query ../../trinity_2.15/Trinity.fasta -out alignments_BLASTn.csv \\\n",
    "-evalue 10 -outfmt 6 -max_target_seqs 1 -num_threads 16\n",
    "\n",
    "# Extracting TRINITY_ID and Accession\n",
    "awk '{print $1, $2}' alignments_BLASTn.csv | sort -u > trinity_taxonomy_ids.txt\n",
    "\n",
    "# List of unique accessions\n",
    "awk '{print $2}' trinity_taxonomy_ids.txt | sort -u > trinity_accessions.txt\n",
    "\n",
    "# Recovering NCBI IDs using accession\n",
    "while read accession; do\n",
    "    taxid=$(blastdbcmd -db nt -entry \"$accession\" -outfmt \"%T\")\n",
    "    echo \"$accession $taxid\"\n",
    "done < trinity_accessions.txt > trinity_accessions_with_taxids.txt\n",
    "\n",
    "# Cleaning IDs with missing accession\n",
    "awk 'NF == 2' trinity_accessions_with_taxids.txt > cleaned_trinity_accessions_with_taxids.txt\n",
    "\n",
    "# Merging previous file with Trinity_ID\n",
    "awk 'NR==FNR {taxid[$1] = $2; next} {print $0, taxid[$2]}' cleaned_trinity_accessions_with_taxids.txt \\\n",
    "trinity_taxonomy_ids.txt > trinity_BLASTn_with_taxids.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715620eb",
   "metadata": {},
   "source": [
    "- 6) Efetch to recover tax information.\n",
    "    - Created an executable fetcher.sh file with the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0889856",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "process_file() {\n",
    "    input_file=$1\n",
    "    output_file=$2\n",
    "    error_log=$3\n",
    "\n",
    "    while read trinity_id accession taxid; do\n",
    "        retry_count=0\n",
    "        max_retries=3\n",
    "        success=0\n",
    "\n",
    "        while [ $retry_count -lt $max_retries ]; do\n",
    "            taxonomy=$(efetch -db taxonomy -id \"$taxid\" -format xml | xtract -pattern LineageEx -block Taxon -sep \":\" -element ScientificName,Rank 2>/dev/null | tr '\\n' ' ')\n",
    "\n",
    "            if [ -n \"$taxonomy\" ]; then\n",
    "                success=1\n",
    "                break\n",
    "            else\n",
    "                retry_count=$((retry_count + 1))\n",
    "                sleep 3  # fine-tune this to avoid rate limits\n",
    "            fi\n",
    "        done\n",
    "\n",
    "        if [ $success -eq 1 ]; then\n",
    "            echo \"$trinity_id $accession $taxid $taxonomy\" >> \"$output_file\"\n",
    "        else\n",
    "            echo \"$trinity_id $accession $taxid ERROR: Taxonomy fetch failed after $max_retries attempts\" >> \"$error_log\"\n",
    "        fi\n",
    "\n",
    "    done < \"$input_file\"\n",
    "}\n",
    "\n",
    "# run\n",
    "process_file \"trinity_BLASTn_with_taxids.csv\" \"trinity_taxonomy_results.csv\" \"trinity_BLASTn_error_log.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc3c375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making it executable and running it\n",
    "chmod +x fetcher.sh\n",
    "./fetcher.sh"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-metal-test",
   "language": "python",
   "name": "tensorflow-metal-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
